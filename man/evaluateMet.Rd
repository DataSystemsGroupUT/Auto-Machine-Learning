% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/evaluateMet.R
\name{evaluateMet}
\alias{evaluateMet}
\title{Evaluate Fitted Model.}
\usage{
evaluateMet(yTrue, pred, metric = "acc")
}
\arguments{
\item{yTrue}{Vector of true labels.}

\item{pred}{Vector of predicted labels.}

\item{metric}{Metric to be used in evaluation:
\itemize{
\item "acc" - Accuracy,
\item "fscore" - Micro-Average of F-Score of each label,
\item "recall" - Micro-Average of Recall of each label,
\item "precision" - Micro-Average of Precision of each label.
}}
}
\value{
Float number representing the evaluation.
}
\description{
Evaluate Predictions obtained from a specific model based on true labels, its predictions, and the evaluation metric.
}
\examples{
\dontrun{
result1 <- autoRLearn(10, 'sampleDatasets/shuttle/train.arff', 'sampleDatasets/shuttle/test.arff')
}

}
